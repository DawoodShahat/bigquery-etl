{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"BigQuery ETL","title":"BigQuery ETL"},{"location":"#bigquery-etl","text":"","title":"BigQuery ETL"},{"location":"mozfun/bits28/","text":"bits28 The bits28 functions provide an API for working with \"bit pattern\" INT64 fields, as used in the clients_last_seen dataset for desktop Firefox and similar datasets for other applications. A powerful feature of the clients_last_seen methodology is that it doesn't record specific metrics like MAU and WAU directly, but rather each row stores a history of the discrete days on which a client was active in the past 28 days. We could calculate active users in a 10 day or 25 day window just as efficiently as a 7 day (WAU) or 28 day (MAU) window. But we can also define completely new metrics based on these usage histories, such as various retention definitions. The usage history is encoded as a \"bit pattern\" where the physical type of the field is a BigQuery INT64, but logically the integer represents an array of bits, with each 1 indicating a day where the given clients was active and each 0 indicating a day where the client was inactive. to_dates Convert a bit pattern into an array of the dates is represents. See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference from_string Convert a string representing individual bits into an INT64. Implementation based on https://stackoverflow.com/a/51600210/1260237 See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference retention Return a nested struct providing booleans indicating whether a given client was active various time periods based on the passed bit pattern. range Return an INT64 representing a range of bits from a source bit pattern. The start_offset must be zero or a negative number indicating an offset from the rightmost bit in the pattern. n_bits is the number of bits to consider, counting right from the bit at start_offset. See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference SELECT -- Signature is bits28.range(offset_to_day_0, start_bit, number_of_bits) mozfun.bits28.range(days_seen_bits, -13 + 0, 7) AS week_0_bits, mozfun.bits28.range(days_seen_bits, -13 + 7, 7) AS week_1_bits FROM telemetry.clients_last_seen WHERE submission_date > '2020-01-01' to_string Convert an INT64 field into a 28-character string representing the individual bits. Implementation based on https://stackoverflow.com/a/51600210/1260237 See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference SELECT [mozfun.bits28.to_string(1), mozfun.bits28.to_string(2), mozfun.bits28.to_string(3)] -- >>> ['0000000000000000000000000001', -- '0000000000000000000000000010', -- '0000000000000000000000000011'] days_since_seen Return the position of the rightmost set bit in an INT64 bit pattern. To determine this position, we take a bitwise AND of the bit pattern and its complement, then we determine the position of the bit via base-2 logarithm; see https://stackoverflow.com/a/42747608/1260237 See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference SELECT mozfun.bits28.days_since_seen(18) -- >> 1 active_in_range Return a boolean indicating if any bits are set in the specified range of a bit pattern. The start_offset must be zero or a negative number indicating an offset from the rightmost bit in the pattern. n_bits is the number of bits to consider, counting right from the bit at start_offset . See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference","title":"bits28"},{"location":"mozfun/bits28/#bits28","text":"The bits28 functions provide an API for working with \"bit pattern\" INT64 fields, as used in the clients_last_seen dataset for desktop Firefox and similar datasets for other applications. A powerful feature of the clients_last_seen methodology is that it doesn't record specific metrics like MAU and WAU directly, but rather each row stores a history of the discrete days on which a client was active in the past 28 days. We could calculate active users in a 10 day or 25 day window just as efficiently as a 7 day (WAU) or 28 day (MAU) window. But we can also define completely new metrics based on these usage histories, such as various retention definitions. The usage history is encoded as a \"bit pattern\" where the physical type of the field is a BigQuery INT64, but logically the integer represents an array of bits, with each 1 indicating a day where the given clients was active and each 0 indicating a day where the client was inactive.","title":"bits28"},{"location":"mozfun/bits28/#to_dates","text":"Convert a bit pattern into an array of the dates is represents. See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference","title":"to_dates"},{"location":"mozfun/bits28/#from_string","text":"Convert a string representing individual bits into an INT64. Implementation based on https://stackoverflow.com/a/51600210/1260237 See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference","title":"from_string"},{"location":"mozfun/bits28/#retention","text":"Return a nested struct providing booleans indicating whether a given client was active various time periods based on the passed bit pattern.","title":"retention"},{"location":"mozfun/bits28/#range","text":"Return an INT64 representing a range of bits from a source bit pattern. The start_offset must be zero or a negative number indicating an offset from the rightmost bit in the pattern. n_bits is the number of bits to consider, counting right from the bit at start_offset. See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference SELECT -- Signature is bits28.range(offset_to_day_0, start_bit, number_of_bits) mozfun.bits28.range(days_seen_bits, -13 + 0, 7) AS week_0_bits, mozfun.bits28.range(days_seen_bits, -13 + 7, 7) AS week_1_bits FROM telemetry.clients_last_seen WHERE submission_date > '2020-01-01'","title":"range"},{"location":"mozfun/bits28/#to_string","text":"Convert an INT64 field into a 28-character string representing the individual bits. Implementation based on https://stackoverflow.com/a/51600210/1260237 See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference SELECT [mozfun.bits28.to_string(1), mozfun.bits28.to_string(2), mozfun.bits28.to_string(3)] -- >>> ['0000000000000000000000000001', -- '0000000000000000000000000010', -- '0000000000000000000000000011']","title":"to_string"},{"location":"mozfun/bits28/#days_since_seen","text":"Return the position of the rightmost set bit in an INT64 bit pattern. To determine this position, we take a bitwise AND of the bit pattern and its complement, then we determine the position of the bit via base-2 logarithm; see https://stackoverflow.com/a/42747608/1260237 See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference SELECT mozfun.bits28.days_since_seen(18) -- >> 1","title":"days_since_seen"},{"location":"mozfun/bits28/#active_in_range","text":"Return a boolean indicating if any bits are set in the specified range of a bit pattern. The start_offset must be zero or a negative number indicating an offset from the rightmost bit in the pattern. n_bits is the number of bits to consider, counting right from the bit at start_offset . See detailed docs for the bits28 suite of functions: https://docs.telemetry.mozilla.org/cookbooks/clients_last_seen_bits.html#udf-reference","title":"active_in_range"},{"location":"mozfun/event_analysis/","text":"Event Analysis These functions are specific for use with the events_daily and event_types tables. By themselves, these two tables are nearly impossible to use since the event history is compressed; however, these stored procedures should make the data accessible. The events_daily table is created as a result of two steps: 1. Map each event to a single UTF8 char which will represent it 2. Group each client-day and store a string that records, using the compressed format, that clients' event history for that day. The characters are ordered by the timestamp which they appeared that day. The best way to access this data is to create a view to do the heavy lifting. For example, to see which clients completed a certain action, you can create a view using these functions that knows what that action's representation is (using the compressed mapping from 1.) and create a regex string that checks for the presence of that event. The view makes this transparent, and allows users to simply query a boolean field representing the presence of that event on that day. create_events_view Create a view that queries the events_daily table. This view currently supports both funnels and event counts. Funnels are created as a struct, with each step in the funnel as a boolean column in the struct, indicating whether the user completed that step on that day. Event counts are simply integers. Usage create_events_view( view_name STRING, project STRING, dataset STRING, funnels ARRAY<STRUCT< funnel_name STRING, funnel ARRAY<STRUCT< step_name STRING, events ARRAY<STRUCT< category STRING, event_name STRING>>>>>>, counts ARRAY<STRUCT< count_name STRING, events ARRAY<STRUCT< category STRING, event_name STRING>>>> ) view_name : The name of the view that will be created. This view will be in the shared-prod project, in the analysis bucket, and so will be queryable at: sql `moz-fx-data-shared-prod`.analysis.{view_name} project : The project where the dataset is located. dataset : The dataset that must contain both the events_daily and event_types tables. funnels : An array of funnels that will be created. Each funnel has two parts: funnel_name : The name of the funnel is what the column representing the funnel will be named in the view. For example, with the value \"onboarding\" , the view can be selected as follows: sql SELECT onboarding FROM `moz-fx-data-shared-prod`.analysis.{view_name} funnel : The ordered series of steps that make up a funnel. Each step also has: step_name : Used to name the column within the funnel and represents whether the user completed that step on that day. For example, within onboarding a user may have completed_first_card as a step; this can be queried at sql SELECT onboarding.completed_first_step FROM `moz-fx-data-shared-prod`.analysis.{view_name} events : The set of events which indicate the user completed that step of the funnel. Most of the time this is a single event. Each event has a category and event_name . counts : An array of counts. Each count has two parts, similar to funnel steps: count_name : Used to name the column representing the event count. E.g. \"clicked_settings_count\" would be queried at sql SELECT clicked_settings_count FROM `moz-fx-data-shared-prod`.analysis.{view_name} events : The set of events you want to count. Each event has a category and event_name . Recommended Pattern Because the view definitions themselves are not informative about the contents of the events fields, it is best to put your query immediately after the procedure invocation, rather than invoking the procedure and running a separate query. This STMO query is an example of doing so. This allows viewers of the query to easily interpret what the funnel and count columns represent. Structure of the Resulting View The view will be created at `moz-fx-data-shared-prod`.analysis.{event_name}. The view will have a schema roughly matching the following: root |-- submission_date: date |-- client_id: string |-- {funnel_1_name}: record | |-- {funnel_step_1_name} boolean | |-- {funnel_step_2_name} boolean ... |-- {funnel_N_name}: record | |-- {funnel_step_M_name}: boolean |-- {count_1_name}: integer ... |-- {count_N_name}: integer ...dimensions... Funnels Each funnel will be a STRUCT with nested columns representing completion of each step The types of those columns are boolean, and represent whether the user completed that step on that day. STRUCT( completed_step_1 BOOLEAN, completed_step_2 BOOLEAN, ... ) AS funnel_name With one row per-user per-day, you can use COUNTIF(funnel_name.completed_step_N) to query these fields. See below for an example. Event Counts Each event count is simply an INT64 representing the number of times the user completed those events on that day. If there are multiple events represented within one count, the values are summed. For example, if you wanted to know the number of times a user opened or closed the app, you could create a single event count with those two events. event_count_name INT64 Examples The following creates a few fields: - collection_flow is a funnel for those that started creating a collection within Fenix, and then finished, either by adding those tabs to an existing collection or saving it as a new collection. - collection_flow_saved represents users who started the collection flow then saved it as a new collection. - number_of_collections_created is the number of collections created - number_of_collections_deleted is the number of collections deleted CALL mozfun.event_analysis.create_events_view( 'fenix_collection_funnels', 'moz-fx-data-shared-prod', 'org_mozilla_firefox', -- Funnels [ STRUCT( \"collection_flow\" AS funnel_name, [STRUCT( \"started_collection_creation\" AS step_name, [STRUCT('collections' AS category, 'tab_select_opened' AS event_name)] AS events), STRUCT( \"completed_collection_creation\" AS step_name, [STRUCT('collections' AS category, 'saved' AS event_name), STRUCT('collections' AS category, 'tabs_added' AS event_name)] AS events) ] AS funnel), STRUCT( \"collection_flow_saved\" AS funnel_name, [STRUCT( \"started_collection_creation\" AS step_name, [STRUCT('collections' AS category, 'tab_select_opened' AS event_name)] AS events), STRUCT( \"saved_collection\" AS step_name, [STRUCT('collections' AS category, 'saved' AS event_name)] AS events) ] AS funnel) ], -- Event Counts [ STRUCT( \"number_of_collections_created\" AS count_name, [STRUCT('collections' AS category, 'saved' AS event_name)] AS events ), STRUCT( \"number_of_collections_deleted\" AS count_name, [STRUCT('collections' AS category, 'removed' AS event_name)] AS events ) ] ); From there, you can query a few things. For example, the fraction of users who completed each step of the collection flow over time: SELECT submission_date, COUNTIF(collection_flow.started_collection_creation) / COUNT(*) AS started_collection_creation, COUNTIF(collection_flow.completed_collection_creation) / COUNT(*) AS completed_collection_creation, FROM `moz-fx-data-shared-prod`.analysis.fenix_collection_funnels WHERE submission_date >= DATE_SUB(current_date, INTERVAL 28 DAY) GROUP BY submission_date Or you can see the number of collections created and deleted: SELECT submission_date, SUM(number_of_collections_created) AS number_of_collections_created, SUM(number_of_collections_deleted) AS number_of_collections_deleted, FROM `moz-fx-data-shared-prod`.analysis.fenix_collection_funnels WHERE submission_date >= DATE_SUB(current_date, INTERVAL 28 DAY) GROUP BY submission_date","title":"Event Analysis"},{"location":"mozfun/event_analysis/#event-analysis","text":"These functions are specific for use with the events_daily and event_types tables. By themselves, these two tables are nearly impossible to use since the event history is compressed; however, these stored procedures should make the data accessible. The events_daily table is created as a result of two steps: 1. Map each event to a single UTF8 char which will represent it 2. Group each client-day and store a string that records, using the compressed format, that clients' event history for that day. The characters are ordered by the timestamp which they appeared that day. The best way to access this data is to create a view to do the heavy lifting. For example, to see which clients completed a certain action, you can create a view using these functions that knows what that action's representation is (using the compressed mapping from 1.) and create a regex string that checks for the presence of that event. The view makes this transparent, and allows users to simply query a boolean field representing the presence of that event on that day.","title":"Event Analysis"},{"location":"mozfun/event_analysis/#create_events_view","text":"Create a view that queries the events_daily table. This view currently supports both funnels and event counts. Funnels are created as a struct, with each step in the funnel as a boolean column in the struct, indicating whether the user completed that step on that day. Event counts are simply integers.","title":"create_events_view"},{"location":"mozfun/event_analysis/#usage","text":"create_events_view( view_name STRING, project STRING, dataset STRING, funnels ARRAY<STRUCT< funnel_name STRING, funnel ARRAY<STRUCT< step_name STRING, events ARRAY<STRUCT< category STRING, event_name STRING>>>>>>, counts ARRAY<STRUCT< count_name STRING, events ARRAY<STRUCT< category STRING, event_name STRING>>>> ) view_name : The name of the view that will be created. This view will be in the shared-prod project, in the analysis bucket, and so will be queryable at: sql `moz-fx-data-shared-prod`.analysis.{view_name} project : The project where the dataset is located. dataset : The dataset that must contain both the events_daily and event_types tables. funnels : An array of funnels that will be created. Each funnel has two parts: funnel_name : The name of the funnel is what the column representing the funnel will be named in the view. For example, with the value \"onboarding\" , the view can be selected as follows: sql SELECT onboarding FROM `moz-fx-data-shared-prod`.analysis.{view_name} funnel : The ordered series of steps that make up a funnel. Each step also has: step_name : Used to name the column within the funnel and represents whether the user completed that step on that day. For example, within onboarding a user may have completed_first_card as a step; this can be queried at sql SELECT onboarding.completed_first_step FROM `moz-fx-data-shared-prod`.analysis.{view_name} events : The set of events which indicate the user completed that step of the funnel. Most of the time this is a single event. Each event has a category and event_name . counts : An array of counts. Each count has two parts, similar to funnel steps: count_name : Used to name the column representing the event count. E.g. \"clicked_settings_count\" would be queried at sql SELECT clicked_settings_count FROM `moz-fx-data-shared-prod`.analysis.{view_name} events : The set of events you want to count. Each event has a category and event_name .","title":"Usage"},{"location":"mozfun/event_analysis/#recommended-pattern","text":"Because the view definitions themselves are not informative about the contents of the events fields, it is best to put your query immediately after the procedure invocation, rather than invoking the procedure and running a separate query. This STMO query is an example of doing so. This allows viewers of the query to easily interpret what the funnel and count columns represent.","title":"Recommended Pattern"},{"location":"mozfun/event_analysis/#structure-of-the-resulting-view","text":"The view will be created at `moz-fx-data-shared-prod`.analysis.{event_name}. The view will have a schema roughly matching the following: root |-- submission_date: date |-- client_id: string |-- {funnel_1_name}: record | |-- {funnel_step_1_name} boolean | |-- {funnel_step_2_name} boolean ... |-- {funnel_N_name}: record | |-- {funnel_step_M_name}: boolean |-- {count_1_name}: integer ... |-- {count_N_name}: integer ...dimensions...","title":"Structure of the Resulting View"},{"location":"mozfun/event_analysis/#funnels","text":"Each funnel will be a STRUCT with nested columns representing completion of each step The types of those columns are boolean, and represent whether the user completed that step on that day. STRUCT( completed_step_1 BOOLEAN, completed_step_2 BOOLEAN, ... ) AS funnel_name With one row per-user per-day, you can use COUNTIF(funnel_name.completed_step_N) to query these fields. See below for an example.","title":"Funnels"},{"location":"mozfun/event_analysis/#event-counts","text":"Each event count is simply an INT64 representing the number of times the user completed those events on that day. If there are multiple events represented within one count, the values are summed. For example, if you wanted to know the number of times a user opened or closed the app, you could create a single event count with those two events. event_count_name INT64","title":"Event Counts"},{"location":"mozfun/event_analysis/#examples","text":"The following creates a few fields: - collection_flow is a funnel for those that started creating a collection within Fenix, and then finished, either by adding those tabs to an existing collection or saving it as a new collection. - collection_flow_saved represents users who started the collection flow then saved it as a new collection. - number_of_collections_created is the number of collections created - number_of_collections_deleted is the number of collections deleted CALL mozfun.event_analysis.create_events_view( 'fenix_collection_funnels', 'moz-fx-data-shared-prod', 'org_mozilla_firefox', -- Funnels [ STRUCT( \"collection_flow\" AS funnel_name, [STRUCT( \"started_collection_creation\" AS step_name, [STRUCT('collections' AS category, 'tab_select_opened' AS event_name)] AS events), STRUCT( \"completed_collection_creation\" AS step_name, [STRUCT('collections' AS category, 'saved' AS event_name), STRUCT('collections' AS category, 'tabs_added' AS event_name)] AS events) ] AS funnel), STRUCT( \"collection_flow_saved\" AS funnel_name, [STRUCT( \"started_collection_creation\" AS step_name, [STRUCT('collections' AS category, 'tab_select_opened' AS event_name)] AS events), STRUCT( \"saved_collection\" AS step_name, [STRUCT('collections' AS category, 'saved' AS event_name)] AS events) ] AS funnel) ], -- Event Counts [ STRUCT( \"number_of_collections_created\" AS count_name, [STRUCT('collections' AS category, 'saved' AS event_name)] AS events ), STRUCT( \"number_of_collections_deleted\" AS count_name, [STRUCT('collections' AS category, 'removed' AS event_name)] AS events ) ] ); From there, you can query a few things. For example, the fraction of users who completed each step of the collection flow over time: SELECT submission_date, COUNTIF(collection_flow.started_collection_creation) / COUNT(*) AS started_collection_creation, COUNTIF(collection_flow.completed_collection_creation) / COUNT(*) AS completed_collection_creation, FROM `moz-fx-data-shared-prod`.analysis.fenix_collection_funnels WHERE submission_date >= DATE_SUB(current_date, INTERVAL 28 DAY) GROUP BY submission_date Or you can see the number of collections created and deleted: SELECT submission_date, SUM(number_of_collections_created) AS number_of_collections_created, SUM(number_of_collections_deleted) AS number_of_collections_deleted, FROM `moz-fx-data-shared-prod`.analysis.fenix_collection_funnels WHERE submission_date >= DATE_SUB(current_date, INTERVAL 28 DAY) GROUP BY submission_date","title":"Examples"},{"location":"mozfun/glean/","text":"glean Functions for working with Glean data. timespan_nanos Returns the number of nanoseconds represented by a Glean timespan struct. See https://mozilla.github.io/glean/book/user/metrics/timespan.html timespan_seconds Returns the number of seconds represented by a Glean timespan struct, rounded down to full seconds. See https://mozilla.github.io/glean/book/user/metrics/timespan.html","title":"glean"},{"location":"mozfun/glean/#glean","text":"Functions for working with Glean data.","title":"glean"},{"location":"mozfun/glean/#timespan_nanos","text":"Returns the number of nanoseconds represented by a Glean timespan struct. See https://mozilla.github.io/glean/book/user/metrics/timespan.html","title":"timespan_nanos"},{"location":"mozfun/glean/#timespan_seconds","text":"Returns the number of seconds represented by a Glean timespan struct, rounded down to full seconds. See https://mozilla.github.io/glean/book/user/metrics/timespan.html","title":"timespan_seconds"},{"location":"mozfun/hist/","text":"hist Functions for working with string encodings of histograms from desktop telemetry. normalize Normalize a histogram. Set sum to 1, and normalize to 1 the histogram bucket counts. extract Return a parsed struct from a string-encoded histogram. We support a variety of compact encodings as well as the classic JSON representation as sent in main pings. The built-in BigQuery JSON parsing functions are not powerful enough to handle all the logic here, so we resort to some string processing. This function could behave unexpectedly on poorly-formatted histogram JSON, but we expect that payload validation in the data pipeline should ensure that histograms are well formed, which gives us some flexibility. For more on desktop telemetry histogram structure, see: https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/collection/histograms.html The compact encodings were originally proposed in: https://docs.google.com/document/d/1k_ji_1DB6htgtXnPpMpa7gX0klm-DGV5NMY7KkvVB00/edit# SELECT mozfun.hist.extract( '{\"bucket_count\":3,\"histogram_type\":4,\"sum\":1,\"range\":[1,2],\"values\":{\"0\":1,\"1\":0}}' ).sum -- 1 SELECT mozfun.hist.extract('5').sum -- 5 merge Merge an array of histograms into a single histogram. The histogram values will be summed per-bucket The count will be summed Other fields will take the mode_last mean Given histogram h, return floor(mean) of the measurements in the bucket. That is, the histogram sum divided by the number of measurements taken. https://github.com/mozilla/telemetry-batch-view/blob/ea0733c/src/main/scala/com/mozilla/telemetry/utils/MainPing.scala#L292-L307 threshold_count Return the number of recorded observations greater than threshold for the histogram. CAUTION: Does not count any buckets that have any values less than the threshold. For example, a bucket with range (1, 10) will not be counted for a threshold of 2. Use threshold that are not bucket boundaries with caution. https://github.com/mozilla/telemetry-batch-view/blob/ea0733c/src/main/scala/com/mozilla/telemetry/utils/MainPing.scala#L213-L239 percentiles Given histogram and list of percentiles, calculate what those percentiles are for the histogram. If the histogram is empty, returns NULL.","title":"hist"},{"location":"mozfun/hist/#hist","text":"Functions for working with string encodings of histograms from desktop telemetry.","title":"hist"},{"location":"mozfun/hist/#normalize","text":"Normalize a histogram. Set sum to 1, and normalize to 1 the histogram bucket counts.","title":"normalize"},{"location":"mozfun/hist/#extract","text":"Return a parsed struct from a string-encoded histogram. We support a variety of compact encodings as well as the classic JSON representation as sent in main pings. The built-in BigQuery JSON parsing functions are not powerful enough to handle all the logic here, so we resort to some string processing. This function could behave unexpectedly on poorly-formatted histogram JSON, but we expect that payload validation in the data pipeline should ensure that histograms are well formed, which gives us some flexibility. For more on desktop telemetry histogram structure, see: https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/collection/histograms.html The compact encodings were originally proposed in: https://docs.google.com/document/d/1k_ji_1DB6htgtXnPpMpa7gX0klm-DGV5NMY7KkvVB00/edit# SELECT mozfun.hist.extract( '{\"bucket_count\":3,\"histogram_type\":4,\"sum\":1,\"range\":[1,2],\"values\":{\"0\":1,\"1\":0}}' ).sum -- 1 SELECT mozfun.hist.extract('5').sum -- 5","title":"extract"},{"location":"mozfun/hist/#merge","text":"Merge an array of histograms into a single histogram. The histogram values will be summed per-bucket The count will be summed Other fields will take the mode_last","title":"merge"},{"location":"mozfun/hist/#mean","text":"Given histogram h, return floor(mean) of the measurements in the bucket. That is, the histogram sum divided by the number of measurements taken. https://github.com/mozilla/telemetry-batch-view/blob/ea0733c/src/main/scala/com/mozilla/telemetry/utils/MainPing.scala#L292-L307","title":"mean"},{"location":"mozfun/hist/#threshold_count","text":"Return the number of recorded observations greater than threshold for the histogram. CAUTION: Does not count any buckets that have any values less than the threshold. For example, a bucket with range (1, 10) will not be counted for a threshold of 2. Use threshold that are not bucket boundaries with caution. https://github.com/mozilla/telemetry-batch-view/blob/ea0733c/src/main/scala/com/mozilla/telemetry/utils/MainPing.scala#L213-L239","title":"threshold_count"},{"location":"mozfun/hist/#percentiles","text":"Given histogram and list of percentiles, calculate what those percentiles are for the histogram. If the histogram is empty, returns NULL.","title":"percentiles"},{"location":"mozfun/json/","text":"json Functions for parsing Mozilla-specific JSON data types. extract_int_map Returns an array of key/value structs from a string representing a JSON map. Both keys and values are cast to integers. This is the format for the \"values\" field in the desktop telemetry histogram JSON representation. mode_last Returns the most frequently occuring element in an array of json-compatible elements. In the case of multiple values tied for the highest count, it returns the value that appears latest in the array. Nulls are ignored.","title":"json"},{"location":"mozfun/json/#json","text":"Functions for parsing Mozilla-specific JSON data types.","title":"json"},{"location":"mozfun/json/#extract_int_map","text":"Returns an array of key/value structs from a string representing a JSON map. Both keys and values are cast to integers. This is the format for the \"values\" field in the desktop telemetry histogram JSON representation.","title":"extract_int_map"},{"location":"mozfun/json/#mode_last","text":"Returns the most frequently occuring element in an array of json-compatible elements. In the case of multiple values tied for the highest count, it returns the value that appears latest in the array. Nulls are ignored.","title":"mode_last"},{"location":"mozfun/map/","text":"map Functions for working with arrays of key/value structs. mode_last Combine entries from multiple maps, determine the value for each key using mozfun.stats.mode_last. sum Return the sum of values by key in an array of map entries. The expected schema for entries is ARRAY >, where the type for value must be supported by SUM, which allows numeric data types INT64, NUMERIC, and FLOAT64. get_key Fetch the value associated with a given key from an array of key/value structs. Because map types aren't available in BigQuery, we model maps as arrays of structs instead, and this function provides map-like access to such fields. get_key_with_null Fetch the value associated with a given key from an array of key/value structs. Because map types aren't available in BigQuery, we model maps as arrays of structs instead, and this function provides map-like access to such fields. This version matches NULL keys as well.","title":"map"},{"location":"mozfun/map/#map","text":"Functions for working with arrays of key/value structs.","title":"map"},{"location":"mozfun/map/#mode_last","text":"Combine entries from multiple maps, determine the value for each key using mozfun.stats.mode_last.","title":"mode_last"},{"location":"mozfun/map/#sum","text":"Return the sum of values by key in an array of map entries. The expected schema for entries is ARRAY >, where the type for value must be supported by SUM, which allows numeric data types INT64, NUMERIC, and FLOAT64.","title":"sum"},{"location":"mozfun/map/#get_key","text":"Fetch the value associated with a given key from an array of key/value structs. Because map types aren't available in BigQuery, we model maps as arrays of structs instead, and this function provides map-like access to such fields.","title":"get_key"},{"location":"mozfun/map/#get_key_with_null","text":"Fetch the value associated with a given key from an array of key/value structs. Because map types aren't available in BigQuery, we model maps as arrays of structs instead, and this function provides map-like access to such fields. This version matches NULL keys as well.","title":"get_key_with_null"},{"location":"mozfun/norm/","text":"norm Functions for normalizing data. fenix_app_info Returns canonical, human-understandable identification info for Fenix sources. The Glean telemetry library for Android by design routes pings based on the Play Store appId value of the published application. As of August 2020, there have been 5 separate Play Store appId values associated with different builds of Fenix, each corresponding to different datasets in BigQuery, and the mapping of appId to logical app names (Firefox vs. Firefox Preview) and channel names (nightly, beta, or release) has changed over time; see the spreadsheet of naming history for Mozilla's mobile browsers . This function is intended as the source of truth for how to map a specific ping in BigQuery to a logical app names and channel. It should be expected that the output of this function may evolve over time. If we rename a product or channel, we may choose to update the values here so that analyses consistently get the new name. The first argument ( app_id ) can be fairly fuzzy; it is tolerant of actual Google Play Store appId values like 'org.mozilla.firefox_beta' (mix of periods and underscores) as well as BigQuery dataset names with suffixes like 'org_mozilla_firefox_beta_stable'. The second argument ( app_build_id ) should be the value in client_info.app_build. The function returns a STRUCT that contains the logical app_name and channel as well as the Play Store app_id in the canonical form which would appear in Play Store URLs. Note that the naming of Fenix applications changed on 2020-07-03, so to get a continuous view of the pings associated with a logical app channel, you may need to union together tables from multiple BigQuery datasets. To see data for all Fenix channels together, it is necessary to union together tables from all 5 datasets. For basic usage information, consider using telemetry.nondesktop_clients_last_seen which already handles the union. Otherwise, see the example below as a template for how construct a custom union. Mapping of channels to datasets: release: org_mozilla_firefox beta: org_mozilla_firefox_beta (current) and org_mozilla_fenix nightly: org_mozilla_fenix (current), org_mozilla_fennec_aurora , and org_mozilla_fenix_nightly -- Example of a query over all Fenix builds advertised as \"Firefox Beta\" CREATE TEMP FUNCTION extract_fields(app_id STRING, m ANY TYPE) AS ( ( SELECT AS STRUCT m.submission_timestamp, m.metrics.string.geckoview_version, mozfun.norm.fenix_app_info(app_id, m.client_info.app_build).* ) ); WITH base AS ( SELECT extract_fields('org_mozilla_firefox_beta', m).* FROM org_mozilla_firefox_beta.metrics AS m UNION ALL SELECT extract_fields('org_mozilla_fenix', m).* FROM org_mozilla_fenix.metrics AS m ) SELECT DATE(submission_timestamp) AS submission_date, geckoview_version, COUNT(*) FROM base WHERE app_name = 'Fenix' -- excludes 'Firefox Preview' AND channel = 'beta' AND DATE(submission_timestamp) = '2020-08-01' GROUP BY submission_date, geckoview_version glean_ping_info Accepts a glean ping_info struct as input and returns a modified struct that includes a few parsed or normalized variants of the input fields. os Normalize an operating system string to one of the three major desktop platforms, one of the two major mobile platforms, or \"Other\". Reimplementation of logic used in the data pipeline: https://github.com/mozilla/gcp-ingestion/blob/a6928fb089f1652856147c4605df715f327edfcd/ingestion-beam/src/main/java/com/mozilla/telemetry/transforms/NormalizeAttributes.java#L52-L74 glean_baseline_client_info Accepts a glean client_info struct as input and returns a modified struct that includes a few parsed or normalized variants of the input fields. metadata Accepts a pipeline metadata struct as input and returns a modified struct that includes a few parsed or normalized variants of the input metadata fields.","title":"norm"},{"location":"mozfun/norm/#norm","text":"Functions for normalizing data.","title":"norm"},{"location":"mozfun/norm/#fenix_app_info","text":"Returns canonical, human-understandable identification info for Fenix sources. The Glean telemetry library for Android by design routes pings based on the Play Store appId value of the published application. As of August 2020, there have been 5 separate Play Store appId values associated with different builds of Fenix, each corresponding to different datasets in BigQuery, and the mapping of appId to logical app names (Firefox vs. Firefox Preview) and channel names (nightly, beta, or release) has changed over time; see the spreadsheet of naming history for Mozilla's mobile browsers . This function is intended as the source of truth for how to map a specific ping in BigQuery to a logical app names and channel. It should be expected that the output of this function may evolve over time. If we rename a product or channel, we may choose to update the values here so that analyses consistently get the new name. The first argument ( app_id ) can be fairly fuzzy; it is tolerant of actual Google Play Store appId values like 'org.mozilla.firefox_beta' (mix of periods and underscores) as well as BigQuery dataset names with suffixes like 'org_mozilla_firefox_beta_stable'. The second argument ( app_build_id ) should be the value in client_info.app_build. The function returns a STRUCT that contains the logical app_name and channel as well as the Play Store app_id in the canonical form which would appear in Play Store URLs. Note that the naming of Fenix applications changed on 2020-07-03, so to get a continuous view of the pings associated with a logical app channel, you may need to union together tables from multiple BigQuery datasets. To see data for all Fenix channels together, it is necessary to union together tables from all 5 datasets. For basic usage information, consider using telemetry.nondesktop_clients_last_seen which already handles the union. Otherwise, see the example below as a template for how construct a custom union. Mapping of channels to datasets: release: org_mozilla_firefox beta: org_mozilla_firefox_beta (current) and org_mozilla_fenix nightly: org_mozilla_fenix (current), org_mozilla_fennec_aurora , and org_mozilla_fenix_nightly -- Example of a query over all Fenix builds advertised as \"Firefox Beta\" CREATE TEMP FUNCTION extract_fields(app_id STRING, m ANY TYPE) AS ( ( SELECT AS STRUCT m.submission_timestamp, m.metrics.string.geckoview_version, mozfun.norm.fenix_app_info(app_id, m.client_info.app_build).* ) ); WITH base AS ( SELECT extract_fields('org_mozilla_firefox_beta', m).* FROM org_mozilla_firefox_beta.metrics AS m UNION ALL SELECT extract_fields('org_mozilla_fenix', m).* FROM org_mozilla_fenix.metrics AS m ) SELECT DATE(submission_timestamp) AS submission_date, geckoview_version, COUNT(*) FROM base WHERE app_name = 'Fenix' -- excludes 'Firefox Preview' AND channel = 'beta' AND DATE(submission_timestamp) = '2020-08-01' GROUP BY submission_date, geckoview_version","title":"fenix_app_info"},{"location":"mozfun/norm/#glean_ping_info","text":"Accepts a glean ping_info struct as input and returns a modified struct that includes a few parsed or normalized variants of the input fields.","title":"glean_ping_info"},{"location":"mozfun/norm/#os","text":"Normalize an operating system string to one of the three major desktop platforms, one of the two major mobile platforms, or \"Other\". Reimplementation of logic used in the data pipeline: https://github.com/mozilla/gcp-ingestion/blob/a6928fb089f1652856147c4605df715f327edfcd/ingestion-beam/src/main/java/com/mozilla/telemetry/transforms/NormalizeAttributes.java#L52-L74","title":"os"},{"location":"mozfun/norm/#glean_baseline_client_info","text":"Accepts a glean client_info struct as input and returns a modified struct that includes a few parsed or normalized variants of the input fields.","title":"glean_baseline_client_info"},{"location":"mozfun/norm/#metadata","text":"Accepts a pipeline metadata struct as input and returns a modified struct that includes a few parsed or normalized variants of the input metadata fields.","title":"metadata"},{"location":"mozfun/overview/","text":"mozfun mozfun is a public GCP project provisioning publicly accessible user-defined functions (UDFs) and other function-like resources.","title":"mozfun"},{"location":"mozfun/overview/#mozfun","text":"mozfun is a public GCP project provisioning publicly accessible user-defined functions (UDFs) and other function-like resources.","title":"mozfun"},{"location":"mozfun/stats/","text":"stats Statistics functions. mode_last Returns the most frequently occuring element in an array. In the case of multiple values tied for the highest count, it returns the value that appears latest in the array. Nulls are ignored. See also: stats.mode_last_retain_nulls , which retains nulls. mode_last_retain_nulls Returns the most frequently occuring element in an array. In the case of multiple values tied for the highest count, it returns the value that appears latest in the array. Nulls are retained. See also: `stats.mode_last, which ignores nulls.","title":"stats"},{"location":"mozfun/stats/#stats","text":"Statistics functions.","title":"stats"},{"location":"mozfun/stats/#mode_last","text":"Returns the most frequently occuring element in an array. In the case of multiple values tied for the highest count, it returns the value that appears latest in the array. Nulls are ignored. See also: stats.mode_last_retain_nulls , which retains nulls.","title":"mode_last"},{"location":"mozfun/stats/#mode_last_retain_nulls","text":"Returns the most frequently occuring element in an array. In the case of multiple values tied for the highest count, it returns the value that appears latest in the array. Nulls are retained. See also: `stats.mode_last, which ignores nulls.","title":"mode_last_retain_nulls"}]}